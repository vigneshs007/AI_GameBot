{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7638c374-753a-4e41-86ca-3ea9cbd3dbe4",
      "metadata": {
        "id": "7638c374-753a-4e41-86ca-3ea9cbd3dbe4"
      },
      "source": [
        "Environment – Tic-Tac-Toe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "783f3011-6c50-4f57-823b-f0a32abfef75",
      "metadata": {
        "id": "783f3011-6c50-4f57-823b-f0a32abfef75"
      },
      "outputs": [],
      "source": [
        "# Step 1: Environment\n",
        "import random\n",
        "\n",
        "class TicTacToeEnv:\n",
        "    def __init__(self, seed=42):\n",
        "        self.rng = random.Random(seed)\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.board = [0]*9\n",
        "        self.current_player = 1\n",
        "        self.done = False\n",
        "        self.winner = 0\n",
        "        return tuple(self.board)\n",
        "\n",
        "    def state(self):\n",
        "        return tuple(self.board)\n",
        "\n",
        "    def available_actions(self):\n",
        "        return [i for i,v in enumerate(self.board) if v==0]\n",
        "\n",
        "    @staticmethod\n",
        "    def _lines():\n",
        "        return [\n",
        "            (0,1,2),(3,4,5),(6,7,8),\n",
        "            (0,3,6),(1,4,7),(2,5,8),\n",
        "            (0,4,8),(2,4,6)\n",
        "        ]\n",
        "\n",
        "    def _check_winner(self):\n",
        "        for a,b,c in self._lines():\n",
        "            s = self.board[a] + self.board[b] + self.board[c]\n",
        "            if s == 3: return 1\n",
        "            if s == -3: return -1\n",
        "        if 0 not in self.board: return 0  # draw\n",
        "        return None  # ongoing\n",
        "\n",
        "    def step(self, action, player):\n",
        "        if self.done: raise ValueError(\"Game over\")\n",
        "        if self.board[action] != 0:\n",
        "            self.done = True\n",
        "            self.winner = -player\n",
        "            reward = -1 if player==1 else +1\n",
        "            return self.state(), reward, True, {\"illegal\": True}\n",
        "\n",
        "        self.board[action] = player\n",
        "        status = self._check_winner()\n",
        "        if status is not None:\n",
        "            self.done = True\n",
        "            self.winner = status\n",
        "            reward = 1 if status==1 else (-1 if status==-1 else 0.2)\n",
        "            return self.state(), reward, True, {}\n",
        "        return self.state(), 0, False, {}\n",
        "\n",
        "    def render(self):\n",
        "        symbols = {1:'X', -1:'O', 0:'.'}\n",
        "        for r in range(3):\n",
        "            print(' '.join(symbols[self.board[r*3+c]] for c in range(3)))\n",
        "        print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb8991fb-1826-46ac-a208-e63b467e669a",
      "metadata": {
        "id": "fb8991fb-1826-46ac-a208-e63b467e669a"
      },
      "source": [
        "✅ Test Environment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "eb0aa8da-00bc-4378-9696-d09f7e51f01c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb0aa8da-00bc-4378-9696-d09f7e51f01c",
        "outputId": "a2f57ccf-2aaa-42dc-fca5-7005868c5a74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ". . .\n",
            ". . .\n",
            ". . .\n",
            "\n",
            "X . .\n",
            ". . .\n",
            ". . .\n",
            "\n"
          ]
        }
      ],
      "source": [
        "env = TicTacToeEnv()\n",
        "env.render()\n",
        "state, reward, done, info = env.step(0,1)\n",
        "env.render()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e80b47f0-c6f4-4f61-ac34-f23b1e93325a",
      "metadata": {
        "id": "e80b47f0-c6f4-4f61-ac34-f23b1e93325a"
      },
      "source": [
        "Opponents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2dbc8897-1905-427c-83dd-a40076f615ef",
      "metadata": {
        "id": "2dbc8897-1905-427c-83dd-a40076f615ef"
      },
      "outputs": [],
      "source": [
        "# Step 2: Opponents\n",
        "import random\n",
        "\n",
        "def opponent_random(env):\n",
        "    return random.choice(env.available_actions())\n",
        "\n",
        "def opponent_rule_based(env):\n",
        "    board = env.board\n",
        "    avail = env.available_actions()\n",
        "\n",
        "    def would_win(action, mark):\n",
        "        tmp = board.copy()\n",
        "        tmp[action] = mark\n",
        "        for a,b,c in TicTacToeEnv._lines():\n",
        "            if tmp[a]+tmp[b]+tmp[c]==3*mark: return True\n",
        "        return False\n",
        "\n",
        "    # 1) Win if possible\n",
        "    for a in avail:\n",
        "        if would_win(a, -1): return a\n",
        "    # 2) Block X\n",
        "    for a in avail:\n",
        "        if would_win(a, 1): return a\n",
        "    # 3) Choose center/corners/sides\n",
        "    for p in [4,0,2,6,8,1,3,5,7]:\n",
        "        if p in avail: return p\n",
        "    return random.choice(avail)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "489f0e56-b2b3-4410-a479-f6d43c5706a9",
      "metadata": {
        "id": "489f0e56-b2b3-4410-a479-f6d43c5706a9"
      },
      "source": [
        "✅ Test Opponent:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3057794c-0485-4a4e-a3bb-061a1768210a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3057794c-0485-4a4e-a3bb-061a1768210a",
        "outputId": "db8015c8-a1af-4595-81d6-942872df0b23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n",
            "4\n"
          ]
        }
      ],
      "source": [
        "env = TicTacToeEnv()\n",
        "print(opponent_random(env))\n",
        "print(opponent_rule_based(env))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "696e0b72-8e7e-4b84-b7a1-0bbc94fca5f7",
      "metadata": {
        "id": "696e0b72-8e7e-4b84-b7a1-0bbc94fca5f7"
      },
      "source": [
        "Step 4: Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "5218e82f-22b6-4b16-bdd3-af7d462147f6",
      "metadata": {
        "id": "5218e82f-22b6-4b16-bdd3-af7d462147f6"
      },
      "outputs": [],
      "source": [
        "def play_episode(env, agent, opponent_fn=opponent_random, agent_starts=True):\n",
        "    s = env.reset()\n",
        "    env.current_player = 1 if agent_starts else -1\n",
        "    done = False\n",
        "    while not done:\n",
        "        if env.current_player == 1:\n",
        "            legal = env.available_actions()\n",
        "            a = agent.select_action(s, legal)\n",
        "            s_next, r, done, _ = env.step(a, 1)\n",
        "            legal_next = env.available_actions() if not done else []\n",
        "            agent.update(s, a, r, s_next, legal_next, done)\n",
        "            s = s_next\n",
        "            env.current_player = -1\n",
        "        else:\n",
        "            a_op = opponent_fn(env)\n",
        "            s, r, done, _ = env.step(a_op, -1)\n",
        "            env.current_player = 1\n",
        "    return env.winner\n",
        "\n",
        "def train(agent, episodes=5000, eval_every=500):\n",
        "    env = TicTacToeEnv()\n",
        "    log = []\n",
        "    for ep in range(1, episodes+1):\n",
        "        agent_starts = (ep%2==0)\n",
        "        opp = opponent_random if ep%4 !=0 else opponent_rule_based\n",
        "        winner = play_episode(env, agent, opponent_fn=opp, agent_starts=agent_starts)\n",
        "        agent.decay_epsilon()\n",
        "        if ep % eval_every == 0:\n",
        "            log.append((ep, winner, agent.epsilon))\n",
        "            print(f\"Episode {ep} | Last winner: {winner} | ε={agent.epsilon:.3f}\")\n",
        "    return log\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4413913a-b413-4eea-a8d8-9ab9ebc24daf",
      "metadata": {
        "id": "4413913a-b413-4eea-a8d8-9ab9ebc24daf"
      },
      "source": [
        "✅ Test Agent:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "07184735-56be-495e-bdee-840d820c841c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "07184735-56be-495e-bdee-840d820c841c",
        "outputId": "174d38bd-22b0-40c5-e614-3f91188e5be2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'QAgent' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1659652521.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'QAgent' is not defined"
          ]
        }
      ],
      "source": [
        "agent = QAgent()\n",
        "log = train(agent, episodes=3000, eval_every=500)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74977181"
      },
      "source": [
        "# Step 3: Agent (Q-learning)\n",
        "import numpy as np\n",
        "\n",
        "class QAgent:\n",
        "    def __init__(self, alpha=0.5, epsilon=1.0, epsilon_decay=0.999, epsilon_min=0.01, gamma=0.9):\n",
        "        self.Q = {} # Q-table\n",
        "        self.alpha = alpha # learning rate\n",
        "        self.epsilon = epsilon # exploration rate\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.epsilon_min = epsilon_min\n",
        "        self.gamma = gamma # discount factor\n",
        "\n",
        "    def get_q(self, state, action):\n",
        "        return self.Q.get((state, action), 0.0)\n",
        "\n",
        "    def select_action(self, state, legal_actions):\n",
        "        if not legal_actions:\n",
        "            return None\n",
        "        if np.random.rand() < self.epsilon:\n",
        "            return np.random.choice(legal_actions) # Explore\n",
        "        else:\n",
        "            q_values = [self.get_q(state, a) for a in legal_actions]\n",
        "            max_q = max(q_values)\n",
        "            # Handle multiple actions with the same max Q-value\n",
        "            best_actions = [legal_actions[i] for i, q in enumerate(q_values) if q == max_q]\n",
        "            return np.random.choice(best_actions) # Exploit\n",
        "\n",
        "    def update(self, state, action, reward, next_state, next_legal_actions, done):\n",
        "        current_q = self.get_q(state, action)\n",
        "        if done:\n",
        "            next_max_q = 0\n",
        "        else:\n",
        "            next_q_values = [self.get_q(next_state, a) for a in next_legal_actions]\n",
        "            next_max_q = max(next_q_values) if next_q_values else 0\n",
        "\n",
        "        new_q = current_q + self.alpha * (reward + self.gamma * next_max_q - current_q)\n",
        "        self.Q[(state, action)] = new_q\n",
        "\n",
        "    def decay_epsilon(self):\n",
        "        self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)"
      ],
      "id": "74977181",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "471b0678-57f6-4257-a7ec-06329169aeb2",
      "metadata": {
        "id": "471b0678-57f6-4257-a7ec-06329169aeb2"
      },
      "source": [
        "Step 5: Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "681cbc8f-524e-44c5-94ea-904d5e7375da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "681cbc8f-524e-44c5-94ea-904d5e7375da",
        "outputId": "15fabecf-3f9d-4377-bc27-26511c1f4349"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 500 | Last winner: -1 | ε=0.606\n",
            "Episode 1000 | Last winner: -1 | ε=0.368\n",
            "Episode 1500 | Last winner: -1 | ε=0.223\n",
            "Episode 2000 | Last winner: -1 | ε=0.135\n",
            "Episode 2500 | Last winner: -1 | ε=0.082\n",
            "Episode 3000 | Last winner: -1 | ε=0.050\n",
            "Vs Random: {1: 328, -1: 147, 0: 25}\n",
            "Vs Rule-Based: {1: 0, -1: 500, 0: 0}\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Evaluation\n",
        "def evaluate(agent, n_games=500, opponent_fn=opponent_rule_based):\n",
        "    env = TicTacToeEnv()\n",
        "    results = {1:0, -1:0, 0:0}\n",
        "    for i in range(n_games):\n",
        "        s = env.reset()\n",
        "        env.current_player = 1 if i%2==0 else -1\n",
        "        done = False\n",
        "        while not done:\n",
        "            if env.current_player == 1:\n",
        "                legal = env.available_actions()\n",
        "                if legal:\n",
        "                    # Use get_q to handle unseen state-action pairs\n",
        "                    q_vals = [agent.get_q(s, a) for a in legal]\n",
        "                    # Handle the case where q_vals is empty if no legal moves\n",
        "                    if q_vals:\n",
        "                        a = legal[int(np.argmax(q_vals))]\n",
        "                        s, r, done, _ = env.step(a, 1)\n",
        "                # The agent's turn is finished, switch player\n",
        "                env.current_player = -1\n",
        "            else:\n",
        "                a_op = opponent_fn(env)\n",
        "                s, r, done, _ = env.step(a_op, -1)\n",
        "                # The opponent's turn is finished, switch player\n",
        "                env.current_player = 1\n",
        "        results[env.winner] += 1\n",
        "    return results\n",
        "\n",
        "# Create and train the agent\n",
        "agent = QAgent()\n",
        "log = train(agent, episodes=3000, eval_every=500)\n",
        "\n",
        "# Evaluate\n",
        "res_rand = evaluate(agent, 500, opponent_random)\n",
        "res_rule = evaluate(agent, 500, opponent_rule_based)\n",
        "print(\"Vs Random:\", res_rand)\n",
        "print(\"Vs Rule-Based:\", res_rule)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27a59728-8591-4fcb-916f-5670a9a3215e",
      "metadata": {
        "id": "27a59728-8591-4fcb-916f-5670a9a3215e"
      },
      "source": [
        "Demo Game"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "c3e31128-aafc-49df-80dd-c7c953c4458e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3e31128-aafc-49df-80dd-c7c953c4458e",
        "outputId": "108fe4fc-01b4-4354-c83b-9d3a56661a25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ". . .\n",
            ". . .\n",
            ". . .\n",
            "\n",
            "X . .\n",
            ". . .\n",
            ". . .\n",
            "\n",
            "X . .\n",
            ". O .\n",
            ". . .\n",
            "\n",
            "X X .\n",
            ". O .\n",
            ". . .\n",
            "\n",
            "X X O\n",
            ". O .\n",
            ". . .\n",
            "\n",
            "X X O\n",
            "X O .\n",
            ". . .\n",
            "\n",
            "X X O\n",
            "X O .\n",
            "O . .\n",
            "\n",
            "Winner: Opponent\n"
          ]
        }
      ],
      "source": [
        "# Step 6: Demo\n",
        "env_demo = TicTacToeEnv()\n",
        "s = env_demo.reset()\n",
        "env_demo.current_player = 1\n",
        "env_demo.render()\n",
        "\n",
        "while not env_demo.done:\n",
        "    if env_demo.current_player == 1:\n",
        "        legal = env_demo.available_actions()\n",
        "        if legal:\n",
        "            q_vals = [agent.Q[(s,a)] for a in legal]\n",
        "            a = legal[int(np.argmax(q_vals))]\n",
        "            s, r, done, _ = env_demo.step(a, 1)\n",
        "        env_demo.render()\n",
        "        env_demo.current_player = -1\n",
        "    else:\n",
        "        a_op = opponent_rule_based(env_demo)\n",
        "        s, r, done, _ = env_demo.step(a_op, -1)\n",
        "        env_demo.render()\n",
        "        env_demo.current_player = 1\n",
        "\n",
        "print(\"Winner:\", {1:\"Agent\", -1:\"Opponent\", 0:\"Draw\"}[env_demo.winner])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f198ffeb-fb57-402d-8c37-a5d3968b06b1",
      "metadata": {
        "id": "f198ffeb-fb57-402d-8c37-a5d3968b06b1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:venv]",
      "language": "python",
      "name": "conda-env-venv-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}